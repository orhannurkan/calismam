{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kyseLBJ_SDkN"
   },
   "source": [
    "# Learning from your previous model!\n",
    "\n",
    "Hey guys! Welcome back to the transfer learning path.\n",
    "In this tutorial you will learn how to use the previous train model to create a new one. Carful, this time will be a bit different than the last transfer learning tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kw-HkybpSpaR"
   },
   "source": [
    "### Progressive resizing\n",
    "\n",
    "If you remember correctly, we've used the VGG-16 model to build our own model to predict if the image we provide as input is a cat or a dog.\n",
    "We also initiate the input of the first layer in the VGG-16 model to accept image of size 64 by 64 shape.\n",
    "This is all well and good but sadly we realize that such image shape reduce the precision for the image prediction, as the image quality is reduced.\n",
    "The objective of this part is to increase progressively the shape of the input to train our model. This will teach you how to use your own model to apply transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JRaowRRCT0uc"
   },
   "source": [
    "### Project overview\n",
    "\n",
    "Lets import and check our previous model\n",
    "with again all the necessary libraries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "KZJ7bMLeXf11",
    "outputId": "1c0c991e-e7cc-4f2a-b998-6b24c050e840"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Dense,GlobalAveragePooling2D,Dropout,Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "PREVIOUS_MODEL_PATH = './64_by_64.h5'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j5WEuhVcYYCo"
   },
   "source": [
    "Lets observe again how our model looks like to clearly understand what we will need to change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "colab_type": "code",
    "id": "5XXYg1VmYXdg",
    "outputId": "daabcbc5-afc6-4891-f70b-093c082fe598"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 12:28:07.296719 140735639835520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0913 12:28:07.318787 140735639835520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0913 12:28:07.347845 140735639835520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0913 12:28:07.562982 140735639835520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0913 12:28:07.563727 140735639835520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0913 12:28:07.574304 140735639835520 deprecation.py:506] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0913 12:28:07.710947 140735639835520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0913 12:28:07.936300 140735639835520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0913 12:28:08.020502 140735639835520 deprecation.py:323] From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 15,239,746\n",
      "Trainable params: 525,058\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "previous_model = load_model(PREVIOUS_MODEL_PATH)\n",
    "previous_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAxYbi2RZEI4"
   },
   "source": [
    "Lets check again how the VGG-16 Model in our layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 774
    },
    "colab_type": "code",
    "id": "TZjq4tkCaP1R",
    "outputId": "707b0425-686f-43a6-c903-1889f9d99ac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "previous_model.layers[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "in5iND5Cfi3f"
   },
   "source": [
    "We can see that our input layer is of shape 64,64,3.\n",
    "However, since we want to increase the details of the image taken for classification, we need to increase the number of pixels the input will take in. Lets double it this time. We will now have a input shape of 128, 128, 3.\n",
    "To do so, we will need to change the input layer of the VGG-16, as well as the first Conv2D layer.\n",
    "\n",
    "Why ?\n",
    "Because the first conv2D layer is mapped to the input layer, meaning that it has a shape of 64 by 64.\n",
    "As we are going to increase the number of imputed pixels to 128 by 128, our new conv2D will have to be of shape 128, 128 as well, while keeping the number of filter to 64.\n",
    "\n",
    "This means that while we froze the other layers of the VGG-16, we will have to re-train the first conv2D to learn on the new input shape, then pass forward the information to the deeper layers who will remain frozen.\n",
    "\n",
    "Why don't we have to change the other layers as well?  Because we will max pool our new conv2D layer of shape 128,128 into a shape 64, 64 which will match the shape of the second Conv2D layer in the VGG-16 model.\n",
    "\n",
    "\n",
    "\n",
    "Now how are we going to proceed?\n",
    "\n",
    "We will first initiate a new model with two layers, one conv2D for input shape 128,128\n",
    "then a maxpooling layer which will divide the shape of the inputs by 2 (or more precisely, the shape of the filter image by 2) as 128 / 2 = 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rFFohqOYOjde"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64,kernel_size=(3,3),input_shape=(128,128,3),activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UC3nRAlxbwHI"
   },
   "source": [
    "\n",
    "From here we just have to add the layers from the VGG-16 to our newly created model.\n",
    "How so ? Since we have already frozen the VGG-16 in our previous model, we just need to loop over it and add each layers to our brand new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GukG6Pqtcwp2"
   },
   "outputs": [],
   "source": [
    "for layer in previous_model.layers[0].layers[2:]:\n",
    "  # here we precise that we want to take all the layers from the second one to the last one in the VGG-16 model.\n",
    "  model.add(layer)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4tv-DeGDdko9"
   },
   "source": [
    "Finally we add all the other layers in our previous model, while freezing them in the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l5dRIJbMdset"
   },
   "outputs": [],
   "source": [
    "for layer in previous_model.layers[1:]:\n",
    "  layer.trainable = False\n",
    "  model.add(layer)\n",
    "  \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAm-AgaggWov"
   },
   "source": [
    "### training and testing our new model\n",
    "\n",
    "time to train and test this new model and check its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 724
    },
    "colab_type": "code",
    "id": "PrEg0abXgfIE",
    "outputId": "46b21d5b-de3b-4bed-d4b5-33492a623383"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# defining the constants for the model training\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "URL_TRAINING = './training_set' \n",
    "URL_TESTING = './test_set' \n",
    "\n",
    "\n",
    "# creating the image generator\n",
    "\n",
    "generator = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "test_generator = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    ")\n",
    "\n",
    "\n",
    "# creating the train and test sets\n",
    "\n",
    "train_set = generator.flow_from_directory(URL_TRAINING, target_size=(128,128), batch_size=BATCH_SIZE)\n",
    "test_set = test_generator.flow_from_directory(URL_TESTING, target_size=(128,128), batch_size=BATCH_SIZE)\n",
    "\n",
    " \n",
    "# fitting the model\n",
    "\n",
    "model.fit_generator(train_set, steps_per_epoch=len(train_set.filenames)//BATCH_SIZE, epochs=EPOCHS, validation_data = test_set, validation_steps=len(test_set.filenames)//BATCH_SIZE )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vY2kc6J3iYRO"
   },
   "source": [
    "Now it is time to test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2vQVOrLJjKa0"
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(test_set, steps=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lEMG9fW2jLYV"
   },
   "source": [
    "Awesome, you can see that our model is more accurate than the previous one!\n",
    "\n",
    "\n",
    "Now it is your turn to create a new model from this one!\n",
    "\n",
    "Try to double the input shape to 256,256 !\n",
    "\n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Transfer Learning Part2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
