{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMtzBNMJs8-s"
   },
   "source": [
    "# Transfer learning in CNN\n",
    "\n",
    "Welcome to this new chapter in CNN.\n",
    "Here you will learn how to use a trained model to stimulate the learning of your own model.\n",
    "\n",
    "This course is divided into three steps:\n",
    "\n",
    "1.   Import and implement a pre-train model in our own model.\n",
    "2.   Freeze layers in the pre-train model\n",
    "3.   Use your own previous models to improve the precision of a brand new one.\n",
    "\n",
    "\n",
    "## General introduction\n",
    "\n",
    "Have you heard of the term \"don't reinvent the wheel\" ?\n",
    "As developers, we are often self determined to create a new application, a new tool or a new software from scratch.\n",
    "However, as much as intriguing and exiting it is, there is a lot of chance that somebody already built your tool in a much better way. Yes, I know it's sad, but there is also a lot of chance that this same tool has been open sourced for you to use freely! Yeah!!!\n",
    "\n",
    "In data science, it is even more the case, as training a model from scratch require a tremendous amount of data requiring weeks of preparations.\n",
    "\n",
    "This is why having the possibility to share knowledge between one model to another became a must, and this phenomenon was baptised: transfer learning\n",
    "\n",
    "\n",
    "#### Transfer learning \n",
    "\n",
    "Transfer learning refer to the situation where what has been learned in one setting â€¦ is exploited to improve generalization in another setting.\n",
    "\n",
    "It allows a model trained on one task to be re-purposed on a second related task. It allow rapid progress or improved performance when modeling the second task.\n",
    "\n",
    "\n",
    "Here is the difference between creating your model from scratch and using Transfer learning:\n",
    "\n",
    "Bellow in Strategy 1, we are creating a model from scratch using only on input data and letting or Neural Network do the heavy lifting over all of our layers.\n",
    "\n",
    "however in Strategy 3, We are actualy using a previous model where we **FREEZE** its layers to freeze the weight saved in each layer of the network, then we add the additional layers for our specific use case.\n",
    "\n",
    "![alt text](https://miro.medium.com/max/5994/1*9t7Po_ZFsT5_lZj445c-Lw.png)\n",
    "\n",
    "\n",
    "#### the 3 adventages of using transfer learning \n",
    "\n",
    "\n",
    "\n",
    "1.   **Higher start**: The initial skill (before refining the model) on the new model is higher than it otherwise would be. In order word you get a boost at the intial phase of the training\n",
    "\n",
    "2.   **Higher slope**: The rate of improvement of skill during training of the source model is steeper than it otherwise would be. Using pre-trained layers you use previous learning to increase the speed of your new model learning rate\n",
    "\n",
    "3.   **Higher asymptote**: The converged skill of the trained model is better than it otherwise would be. The predictions are better\n",
    "\n",
    "\n",
    "![alt text](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Three-ways-in-which-transfer-might-improve-learning.png\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "### Project overview \n",
    "\n",
    "Here we will use a dataset that you are already familiar with: Cat and Dog.\n",
    "You can of course follow this tutorial using any dataset you want. But I recommend following the course using the dataset provided.\n",
    "\n",
    "\n",
    "\n",
    "We will start by talking about the project we would like to do:\n",
    "\n",
    "We would like to create a model that will allow us to categorize an image as a cat or a dog at a high rate of prediction.\n",
    "\n",
    "However, we only have a small number of images to do so: 4000 images of cats and 4000 images of dogs.\n",
    "\n",
    "In order to increase or precision, we will use the VGG-16 model to \"transfer its learning\"\n",
    "\n",
    "\n",
    "### But what is VGG-16 ?\n",
    "\n",
    "Well I am glad you asked Timmy!\n",
    "\n",
    "\n",
    "Here it is :\n",
    "\n",
    "![alt text](https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png)\n",
    "\n",
    "\n",
    "VGG16 is a convolutionary neural network model presented by K. Simonyan and A. Zisserman of the University of Oxford in the newspaper \"Very Deep Convolutional Networks for Large-Scale Image Recognition\".\n",
    "\n",
    "It trained more than 14 million images to predict 1,000 different classes. You could say it's a pretty good model to use as a basic model.\n",
    "\n",
    "\n",
    "By the way, you need to be sure now that you understand the different layers described on the image!\n",
    "\n",
    "Can you guess what the full neck + Relu is in Keras?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Coding time\n",
    "\n",
    "We will start by creating a new model by using VGG-16 as the base layer,\n",
    "Then we will add a couple of Dense layers before finishing with a softmax layer with 2 nodes to predict wether we have a cat or a dog.\n",
    "\n",
    "Let start with using the VGG-16 as our base layer.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VD-ZTQn7Ll3h"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 12:04:50.797950 140735639835520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0913 12:04:50.818048 140735639835520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0913 12:04:50.828281 140735639835520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0913 12:04:50.859532 140735639835520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 7s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0913 12:04:58.349766 140735639835520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0913 12:04:58.350694 140735639835520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense,GlobalAveragePooling2D,Dropout,Flatten, Conv2D, MaxPooling2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# lets initialize the VGG-16 model\n",
    "# We then remove the final layer of the model as we will add our own to only classify cats and dogs\n",
    "# We also decide the size of the input images: here they are 64px by 64px.\n",
    "\n",
    "prior_model = VGG16(weights='imagenet',include_top=False, input_shape=(64,64,3))\n",
    "\n",
    "# lets create our model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# and here we add a all the VGG16 as a layer\n",
    "\n",
    "model.add(prior_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mKJzyIdgPXIR"
   },
   "source": [
    "We can now Check how our model looks like by using the summary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "WNy2RDb7Ov9Q",
    "outputId": "c49e6e2c-579e-40c0-859f-afec6e446a42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 2, 2, 512)         14714688  \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# apply the summary method on the model\n",
    "#----- HERE -------\n",
    "\n",
    "\n",
    "\n",
    "#------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "czyJT4KXPwjl"
   },
   "source": [
    "Pay attention to the layer type: Model!\n",
    "\n",
    "With Keras, you can actually add a full model as a layer.\n",
    "\n",
    "Lets check now how this layer/model is composed of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "GAd01rxYUyae",
    "outputId": "69436fe3-d050-4f2e-fa7a-0fbdbbab5e35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.layers[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4SzIEg9VO5B"
   },
   "source": [
    "We see that VGG-16 is composed of Conv2D layers.\n",
    "and its final layer is a MaxPooling2D layer.\n",
    "\n",
    "In order to finish our model, we need to flatten it before providing it a Dense layer for the classification.\n",
    "\n",
    "You could add a couple of additional layers such as a Dropout or an other Dense layer before adding the softmax's one just like bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JgpfWllVxmS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0913 12:05:07.366996 140735639835520 deprecation.py:506] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "cKPXz32zV7-4",
    "outputId": "3f86f00d-55b3-4ce0-c11d-1f84488cea7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 15,239,746\n",
      "Trainable params: 15,239,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# lets check the summary of our model \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tVEREMWAWNxe"
   },
   "source": [
    "## Freezing the layers of our prior model\n",
    "\n",
    "Now that we have all the layers set up, we need to freeze those within the prior model and this for a simple reason: **we don't want to train it again as we will need its knowledge to boost the learning and precision of our own model !!!**\n",
    "\n",
    "To do so, we are going to loop over all the layers in the VGG model and set them to learning false, \"freezing\" the weights already saved inside the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KkPHlYxUYeds"
   },
   "outputs": [],
   "source": [
    "for layers in model.layers[0].layers: # looping over each layers in layer 0 to freeze them\n",
    "  layers.trainable = False\n",
    "\n",
    "model.layers[0].trainable = False # freezing layer 0 as well for good measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dv7EX5q2ZQNV"
   },
   "source": [
    "Now that our model is ready: it's time for you to do the next steps for image classifications.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZHfChKH8ZZoH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0913 12:05:16.806025 140735639835520 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1589 images belonging to 2 classes.\n",
      "Found 378 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0913 12:05:17.147226 140735639835520 deprecation.py:323] From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49/49 [==============================] - 20s 416ms/step - loss: 0.6409 - acc: 0.6773 - val_loss: 0.5976 - val_acc: 0.6903\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 21s 423ms/step - loss: 0.5379 - acc: 0.7263 - val_loss: 0.4990 - val_acc: 0.7225\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 21s 434ms/step - loss: 0.5221 - acc: 0.7455 - val_loss: 0.6107 - val_acc: 0.6879\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 21s 437ms/step - loss: 0.5344 - acc: 0.7308 - val_loss: 0.4916 - val_acc: 0.7514\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 22s 442ms/step - loss: 0.4922 - acc: 0.7576 - val_loss: 0.4731 - val_acc: 0.7746\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 21s 419ms/step - loss: 0.4757 - acc: 0.7700 - val_loss: 0.4945 - val_acc: 0.7832\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 21s 427ms/step - loss: 0.5199 - acc: 0.7502 - val_loss: 0.5144 - val_acc: 0.7254\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 20s 411ms/step - loss: 0.4627 - acc: 0.7722 - val_loss: 0.5205 - val_acc: 0.7659\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 20s 410ms/step - loss: 0.4971 - acc: 0.7576 - val_loss: 0.4819 - val_acc: 0.7486\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 21s 422ms/step - loss: 0.4698 - acc: 0.7665 - val_loss: 0.5459 - val_acc: 0.7370\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 20s 415ms/step - loss: 0.4797 - acc: 0.7662 - val_loss: 0.4983 - val_acc: 0.7457\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 21s 421ms/step - loss: 0.4456 - acc: 0.7946 - val_loss: 0.4905 - val_acc: 0.7457\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 21s 420ms/step - loss: 0.4491 - acc: 0.7809 - val_loss: 0.5008 - val_acc: 0.7386\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 21s 422ms/step - loss: 0.4530 - acc: 0.7873 - val_loss: 0.4708 - val_acc: 0.7688\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 20s 415ms/step - loss: 0.4408 - acc: 0.7805 - val_loss: 0.4724 - val_acc: 0.7919\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 20s 412ms/step - loss: 0.4449 - acc: 0.7815 - val_loss: 0.4854 - val_acc: 0.7688\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 20s 411ms/step - loss: 0.4499 - acc: 0.7898 - val_loss: 0.4721 - val_acc: 0.7543\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 20s 413ms/step - loss: 0.4092 - acc: 0.8093 - val_loss: 0.4621 - val_acc: 0.7746\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 21s 431ms/step - loss: 0.4537 - acc: 0.7917 - val_loss: 0.4640 - val_acc: 0.7486\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 22s 449ms/step - loss: 0.4385 - acc: 0.7892 - val_loss: 0.4604 - val_acc: 0.7514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb4288d358>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# defining the constants for the model training\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "URL_TRAINING = './training_set' \n",
    "URL_TESTING = './test_set' \n",
    "\n",
    "\n",
    "# creating the image generator\n",
    "\n",
    "generator = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "test_generator = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    ")\n",
    "\n",
    "\n",
    "# creating the train and test sets\n",
    "\n",
    "train_set = generator.flow_from_directory(URL_TRAINING, target_size=(64,64), batch_size=BATCH_SIZE)\n",
    "test_set = test_generator.flow_from_directory(URL_TESTING, target_size=(64,64), batch_size=BATCH_SIZE)\n",
    "\n",
    " \n",
    "# fitting the model\n",
    "\n",
    "model.fit_generator(train_set, steps_per_epoch=len(train_set.filenames)//BATCH_SIZE, epochs=EPOCHS, validation_data = test_set, validation_steps=len(test_set.filenames)//BATCH_SIZE )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ii0YmbpZrnkU"
   },
   "source": [
    "### Testing\n",
    "\n",
    "Now it's time to test our brand new model using transfer learning!\n",
    "Then save it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYeQj-tsrupT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "TEST_IMAGE_URL = './test_image.jpg'\n",
    "\n",
    "test_image = image.load_img( TEST_IMAGE_URL , target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rcgFrSqbtZvj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.448882337615424, 0.7549407107556761]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_set, steps=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Okh5LF6luU8F"
   },
   "outputs": [],
   "source": [
    "# time to save the model\n",
    "\n",
    "PATH = './64_by_64.h5'\n",
    "\n",
    "model.save(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eyyMMoLUuFgI"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "\n",
    "Here we go! You have now mastered the the super power of transfer learning:\n",
    "\n",
    "1.   You know how to use a previous model as the a launching pad for a new model.\n",
    "\n",
    "\n",
    "2.   You know how to freeze layers in a model\n",
    "\n",
    "\n",
    "Next stop we will use the model we've just saved in to use it as the base of a brand new model in order to increase its accuracy using Progressive Resizing .\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Transfer Learning Part1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
